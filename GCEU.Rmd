---
title: "Analisis temporal de la expulsion de gases de efecto invernadero europeos"
author: "Emilio Coronado"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Resumen

Este proyecto consiste en el estudio de las series temporales sobre un caso práctico. Se implementaran para ello diversos métodos estadísticos con el fin de crear modelos que se ajusten lo mejor posible a nuestro caso practico. Tales métodos como los modelos ARIMA nos permitirán modelar y predecir estos procesos estocásticos. Además de estas técnicas se utilizarán cartografías para la previsualización de estas series temporales.

El estudio de nuestro caso práctico recopila información de los gases de efecto invernadero expulsados por la unión europea desde el año 2008 hasta el primer cuatrimestre de 2025. 

## Obtención y tratamiento de los datos.

### Obtención de los datos a traves de la libreria de eurostat

Los datos utilizados para este estudio los obtenemos via eurostat. Este es el enlace: <https://ec.europa.eu/eurostat/databrowser/view/env_ac_aigg_q/default/table?lang=en>

```{r warnings = FALSE}
library(eurostat)
datos = get_eurostat("env_ac_aigg_q")
View(datos)
unique(datos$unit)
```

Los datos descargados son un un proceso estocastico que transcurre desde el 2010-01-01 hasta el 2023-01-01 y va aumentando de forma trimestral periodicamente.

### Depuración de los datos a través de la libreria dplyer

La principal variable de medición de interés es THS_T (Toneladas de gases de efecto invernadero expulsados).

```{r warnings = FALSE }
library(dplyr)

datosTT <- datos %>%
  filter(unit=="THS_T") %>%
  filter(geo!="EU27_2020") 
View(datosTT)
```

Este primer filtrado de los datos se realiza para la posterior visualización y mapeo de los paises europeos.

## Mapeo y visualización de los datos.

### Obtención de las cartografias.

Para la creación de los mapas es necesario la descarga de una cartografía que contenga los paises de la Unión Europea y esto lo realizamos a través de la página de eurostat. Este es el enlace: <https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts>

```{r warnings = FALSE }
library(sf)
library(tmap)

EU_MAP<-st_read("C:/EMILIO/UNIVERSIDAD/2022-2023/segundo cuatrimestre/TFG/NUTS_RG_60M_2021_3035.shp")
summary(EU_MAP)
summary(EU_MAP$LEVL_CODE)
```

```{r warnings = FALSE }
st_crs(EU_MAP)
```

Obtenemos el sistema de referencia que se utiliza en esta cartografía, así como los paises y sus repectivas islas ilustradas en el.

```{r warnings = FALSE }
tm_shape(EU_MAP)+
  tm_borders()
```

Las graficamos para visualizar y observamos como la cartografia contiene a parte de los paises todos los respectivos multipoligonos asociados a los pueblos y las comunidades autonomas.Por eso es necesario realizar un filtro en la cartografia y quedarnos solo con los NUTS=0 es decir los paises.

```{r warnings = FALSE }
EU_MAP <- EU_MAP %>%
    filter(LEVL_CODE==0)

tm_shape(EU_MAP)+
  tm_borders()
```

Una vez que nuestra cartografia se coresponde con nuestro objetivo de estudio es momento de unir los datos a la cartografia. Pero nuestra base de datos no contiene informacion de todos los paises pertenecientes a la cartografia por tanto habrá que unirlos solo para los que tenemos información.

### Unión con los datos.

```{r warnings = FALSE}
EU_mapa<-dplyr::left_join(EU_MAP, datosTT, by=c("NUTS_ID"="geo"))

EU_mapa <- EU_mapa %>%
  filter(values != "NA")

```

### Transformación del mapa para la visualización.

Filtramos un trimestre aleatorio para visualizar si todo esta en orden.

```{r warnings = FALSE}
EU_mapa2207 <- EU_mapa %>%
  filter(TIME_PERIOD=="2024-07-01")

tm_shape(EU_mapa2207,)+
  tm_fill(palette ="Blues",col = "values",style = "quantile")
```

La cartografia por culpa de las islas de algunos paises queda muy alejada y la visualización no es buena, por lo que transformamos la caja para visualizar mejor.


Generamos una BBDD con las medias de los valores de cada pais a lo largo del tiempo para poder visualizar bien la importancia de cada país.

```{r}
EU_mapa_media <- EU_mapa %>%
    group_by(NUTS_NAME) %>%        # agrupa por país (ajusta el nombre si es otro, ej. "name")
    summarise(media_value = mean(values, na.rm = TRUE)) %>% 
    ungroup()

#ahora visualizamos la importancia de cada país.
tmap_mode("view")

bbox_eu <- st_bbox(c(xmin = -20, ymin = 30, xmax = 40, ymax = 67), crs = 4326)


tm_shape(EU_mapa_media, bbox = bbox_eu) +
  tm_polygons(
    fill = "media_value",
    fill.scale = tm_scale(
      breaks = c(0, 14000, 36000, 68000, 92000, 150000, 280000),
      values = "brewer.yl_or_rd",  # antes: "YlOrRd"
      labels = c("≤ 14k", "14k – 36k", "36k – 68k", "68k – 92k", "92k - 150k",">150k")
    ),
    fill.legend = tm_legend(title = "Toneladas GEI expulsadas", outside = TRUE)
  ) +
  tm_view(view.zoom = 5) +
  tm_layout(frame = FALSE) +
  tm_title("Emisiones de Gases de Efecto Invernadero en media en Europa 2008-2024")

```

Visualizamos como claramente Alemania es el país que más GEI expulsa, seguido por Francia, Italia y Polonia.

############################################################################################################################################################################################################################################################################################# 

## Depuración de los datos y transformación a series temporales.

Para empezar vamos a filtrar nuestra base de datos y crear nuestros objetos en series temporales para su posterior analisis. Lo primero va a ser visualizar las gráficas para obtener información de su comportamiento.

```{r warnings = FALSE }
library(dplyr)
library(forecast)
library(ggplot2)
library(stats)

datosEU_THS_T <- datos %>%
  filter(unit=="THS_T") %>%
  filter(geo=="EU27_2020") %>%
  filter(nace_r2=="TOTAL_HH") %>%
  arrange(TIME_PERIOD)

datosEU_THS_T.ts <- ts(datosEU_THS_T$values,end=c(2025,1),frequency =4)
View(datosEU_THS_T)

ggtsdisplay(datosEU_THS_T.ts,main="Expulsion de gases de efecto invernadero en EUROPA",xlab="AÑO",ylab="MIlies de toneladas")


fitTHS <- decompose(datosEU_THS_T.ts, type='additive')
autoplot(fitTHS)+
  labs(title = "Expulsion de gases de efecto invernadero en Europa",                   
       x = "Tiempo",
       y = "Miles de toneladas",
       colour = "Gears")+
    theme_bw()
```

Se observa una estacionalidad trimestral super clara a parte de una tendencia decreciente a lo largo de toda la serie salvo por el momento del efecto inverso del covid. También observamos una falta de estacionariedad clara y por tanto ni nos fijamos en los coeficientes de autocorrelación.

Creamos otra grafica para visualizar Mejor:

```{r warnings = FALSE }
autoplot(datosEU_THS_T.ts, series="Serie Temporal") + 
    autolayer(trendcycle(fitTHS), series="Tendencia") +
    labs(title = "Expulsión de gases de efecto invernadero en Europa",      
       x = "Años",
       y = "Miles de toneladas"
       ) + 
    theme_bw()
```

Una vez visualizado la tendencia de forma mas grafica pasamos a intentar entender mejor la estacionaidad de nuestra serie.

```{r}
ggseasonplot(datosEU_THS_T.ts)
summary(datosEU_THS_T$values)
```

Y como podemos observar, hay una clara estacionalidad. En los segundos y terceros trimestres del año los europeos expulsamos menos gases de efecto invernadero que en el primer y cuarto trimestre. Lo más probable debido a las temperaturas bajas de esos momentos(otoño/invierno) y el uso de energías contaminantes para la generación de calor.

Pasamos a crear una última grafica interactiva que nos permite saber los valores para cada momento temporal.

```{r}
# Convertir a millones de toneladas para visualizar mejor
datosEU_THS_T_mill <- datosEU_THS_T.ts / 1e6

library(dygraphs)

dygraph(datosEU_THS_T_mill,
        main ="Expulsión de gases de efecto invernadero por Europa",
        xlab = "Años",
        ylab = "Millones de toneladas") 


```

## Metodologia Box_Jenkins

### Primera Etapa:Estacionarización de las series.

Como habiamos dicho anteriormente se ha observado claramente falta de estacionariedad y por tanto tendremos que estabilizar la serie y desestacionalizarla.

#### Diferenciaciones.

Pasamos a probar cuantas diferenciaciones serán necesarias para estabilizar las series.

```{r warnings = FALSE }
ndiffs(datosEU_THS_T.ts)#regulares
nsdiffs(datosEU_THS_T.ts)#estacionales
```

Por tanto va a ser necesario realizar una diferencia regular y una estacional para estacionarizar las dos series temporales del estudio.

##### Diferenciación Regular

```{r warnings = FALSE }
library(forecast)
diff.datosEU_THS_T.ts<-diff(datosEU_THS_T.ts)
plot(datosEU_THS_T.ts,main="serie sin diferenciar",col="purple")
plot(diff.datosEU_THS_T.ts,main="serie diferenciada regularmente",col="purple")
plot(decompose(diff.datosEU_THS_T.ts))
```

Ahora observamos como las series se han estabilizado en media, pero siguen conteniendo la parte estacional y aleatoria del modelo, por ello tenemos que diferenciar estacionalmente.

##### Diferenciación estacional

```{r warnings = FALSE }
diff.datosEU_THS_T.ts.4<-diff(diff.datosEU_THS_T.ts, lag = 4)
plot(datosEU_THS_T.ts,main="serie sin diferenciar",col="purple")
plot(diff.datosEU_THS_T.ts.4,main="serie con una diferencia regular y otra estacional",col="purple")
```

No observamos heterocedasticidad y por tanto no va a ser necesaria hacer ninguna transformación logaritmica o de box-cox. A parte podemos confirmar como se ha eliminado la estacionalidad de la serie y por tanto podemos pasar a intentar visualizar las autocorrelaciones del modelo estacionario para que nos de una idea de que modelo ARIMA nos permitirá modelar dicha serie.

Una vez supuesta la hipótesis de estacionariedad hay que comprobarla y eso lo relizamos a traves del contraste dickey fuller aumentado.

##### Contraste de Estacionariedad

```{r warnings = FALSE }
library(tseries)
adf<-adf.test(diff.datosEU_THS_T.ts.4)
adf$p.value
```

Hay evidencias estadísticas suficientes para rechazar la hipótesis nula de raiz unitaria ya que el pvalor obtenido es menor a 0.01, es decir, menor que el nivel de confianza del test. Por tanto la serie se puede considerar estacionaria en media y en varianza.

#### Visualización de las Autocorrelaciones.

```{r warnings = FALSE }
Acf(diff.datosEU_THS_T.ts.4)
Pacf(diff.datosEU_THS_T.ts.4)
ggtsdisplay(diff.datosEU_THS_T.ts.4)
```

Observamos como decrece rapidamente la funcion de autocorrelacion simple y que en la función de autocorelacion parcial sobresale el primer y cuarto autorregresor, por tanto el modelo ARIMA puede que necesite un paremetro p=1 o 4 a parte de alguna diferenciación y por tanto su parametro d puede que tome el valor de la unidad también.

### Segunda Etapa:Modelización de las series.

#### Detección de los modelos ARIMA

Una vez que hayamos conseguido que la serie sea estacionaria para obtener información de sus autocorrelaciones es hora de identificicar los posibles modelos que mejor se ajusten a nuestra serie original. Para ello probamos distintos modelos ARIMA para a posteriori decidir cual nos convence mas a través de los estadísticos Akaike y BIC.

```{r warnings = FALSE }
library(forecast)
arima1<- Arima(datosEU_THS_T.ts, order=c(0,1,2), seasonal=list(order=c(0,1,1),period=4))
arima2<- Arima(datosEU_THS_T.ts, order=c(1,1,0), seasonal=list(order=c(1,1,1),period=4))
arima3<- Arima(datosEU_THS_T.ts, order=c(1,1,1), seasonal=list(order=c(1,1,0),period=4))
arima4<- Arima(datosEU_THS_T.ts, order=c(1,1,1), seasonal=list(order=c(1,1,1),period=4))
arima5<- Arima(datosEU_THS_T.ts, order=c(1,1,2), seasonal=list(order=c(1,1,1),period=4))
arima6<- Arima(datosEU_THS_T.ts, order=c(0,1,1), seasonal=list(order=c(0,1,1),period=4))
arima7<- Arima(datosEU_THS_T.ts, order=c(1,1,0), seasonal=list(order=c(1,1,0),period=4))
arima8<- Arima(datosEU_THS_T.ts, order=c(1,0,0), seasonal=list(order=c(0,1,1),period=4))
arima9<- Arima(datosEU_THS_T.ts, order=c(0,1,0), seasonal=list(order=c(0,1,1),period=4))

```

#### Elección del modelo a través de los estadisticos.

```{r warnings = FALSE }
#Para la serie de miles de toneladas
AIC(arima1,arima2,arima3,arima4,arima5,arima6,arima7,arima8,arima9)
BIC(arima1,arima2,arima3,arima4,arima5,arima6,arima7,arima8,arima9)
```

Según el estadístico akaike el modelo que minimiza la perdida de informacíon sería el arima6 y luego el arima9;

ARIMA6 (p=0,d=1,q=1)(P=0,D=1,Q=1)4

ARIMA9 (p=0,d=1,q=0)(P=0,D=1,Q=1)4

#### Diagnosis del modelo a través de los residuos.

visualizamos los errores de los modelos para luego contrstar la normalidad de estos:

```{r warnings = FALSE }
checkresiduals(arima6, test=FALSE)
```

Parecen que se adecuan a una distribución normal, pero para estar seguros vamos a realizar el contraste de shapiro-Wilk de normalidad que compara la hipótesis nula de normalidad con la hipótesis alternativa de no normalidad.

```{r warnings = FALSE }
#library(printr)
shapiro.test(arima6$residuals)
shapiro.test(arima9$residuals)
```

En modelos ARIMA para series macroeconómicas o ambientales, la normalidad perfecta de residuos rara vez se cumple.

```{r}
checkresiduals(arima6)
```

Tu SARIMA(0,1,1)(0,1,1)[4] es válido estadísticamente. Es normal que Shapiro-Wilk dé p \< 0.05 aunque Ljung-Box sea correcto. Lo importante aquí es el Ljung-Box, no la normalidad perfecta.

```{r}
checkresiduals(arima9)
```

Vamos que el pvalor de este arima9 es bastante peor que el del arima6, y como los estadísticos akaike y BIC también les pasaba levemente eso lo descartamos y nos quedamos definitivamente con el modelo arima6.

Ahora pasamos a ver si los parametros de nuestros modelos son significativos.

```{r warnings = FALSE }
library(lmtest)
#tsoutliers(arima7$residuals)
coeftest(arima6) #el parámetro de media movil etsacional sale significativo.
```

En el modelo SARIMA(0,1,1)(0,1,1)[4], el coeficiente estacional SMA(1) resulta altamente significativo (p \< 0.001), lo que confirma una fuerte dependencia estacional trimestral en las emisiones de gases de efecto invernadero de la UE. El coeficiente MA(1) presenta un valor próximo a la significación estadística (p ≈ 0.08), lo cual, junto con los criterios de información más bajos y la ausencia de autocorrelación en los residuos, justifica su inclusión. Por tanto, el modelo se considera adecuadamente especificado para realizar pronósticos.

```{r warnings = FALSE }
Box.test(arima6$residuals, lag = 20, type = "Ljung-Box")


```

Como el p-valore(0.618) supera al nivel de significación 0.05, afirmamos la hipótesis nula y por tanto confirmamos que los residuos estan incorrelados. De tal manera ahora tenemos nuestro modelo comprobado y podemos pasar a predecir con el.

```{r}
forecast_arima6 <- forecast(arima6, h = 8)
autoplot(forecast_arima6)

```

### Tercera etapa: Predicción.

Pasamos a visualizar las predicciones para la serie de toneladas de gases de efecto invernadero expulsados per cápita.

```{r warnings = FALSE }
library(forecast)

prediccionesTHS<-forecast(arima6, level = c(95), h = 10)
autoplot(prediccionesTHS, main= "Expulsión de gases de efecto invernadero por trimestre en Europa")
```

```{r}
library(forecast)
library(dygraphs)

prediccionesTHS <- forecast(arima6, level = 95, h = 10)

dygraphs::dygraph(
  cbind(Serie = datosEU_THS_T.ts, Prediccion = prediccionesTHS$mean),
  main = "Expulsión de gases de efecto invernadero por trimestre en Europa"
)

```

```{r}
library(forecast)
library(dygraphs)

# Escalar a millones de toneladas
serie_mill <- datosEU_THS_T.ts / 1e6

# Forecast y escala
prediccionesTHS <- forecast(arima6, level = 95, h = 10)
pred_mill <- prediccionesTHS$mean / 1e6

dygraph(
  cbind(Serie = serie_mill, Predicción = pred_mill),
  main = "GEI expulsados por la UE"
) %>%
  dySeries("Serie", label = "Histórico", strokeWidth = 2) %>%
  dySeries("Predicción", label = "Pronóstico", strokeWidth = 3, strokePattern = "dashed") %>%
  dyAxis("y", label = "Millones de toneladas") %>%
  dyAxis("x", label = "Año") %>%
  dyOptions(
    drawGrid = TRUE,
    useDataTimezone = FALSE,
    fillGraph = FALSE,
    strokeWidth = 2,
    titleHeight = 40
  ) %>%
  dyLegend(show = "always") %>%
  dyHighlight(
    highlightCircleSize = 5,
    highlightSeriesBackgroundAlpha = 0.25,
    hideOnMouseOut = FALSE
  ) %>%
  dyRangeSelector(height = 30)

```

```{r}
library(dplyr)
library(ggplot2)
library(zoo)     # para yearqtr
library(scales)  # para etiquetas bonitas

# Escala a millones
serie_mill <- as.numeric(datosEU_THS_T.ts) / 1e6
ti <- as.yearqtr(time(datosEU_THS_T.ts))

df_q <- tibble::tibble(
  Year    = as.integer(format(ti, "%Y")),
  Quarter = factor(format(ti, "Q%q"), levels = c("Q1","Q2","Q3","Q4")),
  Value   = serie_mill
)

ggplot(df_q, aes(x = factor(Year), y = Quarter, fill = Value)) +
  geom_tile() +
  scale_fill_viridis_c(name = "Mill. t") +
  labs(title = "Mapa de calor: emisiones por trimestre y año",
       x = "Año", y = "Trimestre") +
  theme_minimal(base_size = 12) +
  theme(panel.grid = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))


```

```{r}
ggplot(df_q, aes(x = Quarter, y = Value)) +
  geom_boxplot(outlier.alpha = 0.3) +
  geom_jitter(width = 0.1, alpha = 0.4) +
  scale_y_continuous(labels = label_number(big.mark = ".", decimal.mark = ",")) +
  labs(title = "Distribución histórica por trimestre",
       x = "Trimestre", y = "Millones de toneladas") +
  theme_minimal(base_size = 12)
```

```{r}
library(forecast)
library(dplyr)
library(tidyr)
library(zoo)
library(DT)

# --- 1) Serie y forecast en millones ---
serie_mill <- as.numeric(datosEU_THS_T.ts) / 1e6
pred <- forecast(arima6, h = 10)
pred_mill <- as.numeric(pred$mean) / 1e6

# --- 2) Índices de tiempo correctos (trimestral) ---
ti_hist <- as.yearqtr(time(datosEU_THS_T.ts))
ti_pred <- as.yearqtr(time(pred$mean))

df_hist <- tibble(
  Year    = as.integer(format(ti_hist, "%Y")),
  Quarter = factor(format(ti_hist, "Q%q"), levels = c("Q1","Q2","Q3","Q4")),
  Value   = serie_mill,
  Pred    = FALSE
)

df_pred <- tibble(
  Year    = as.integer(format(ti_pred, "%Y")),
  Quarter = factor(format(ti_pred, "Q%q"), levels = c("Q1","Q2","Q3","Q4")),
  Value   = pred_mill,
  Pred    = TRUE
)

df <- bind_rows(df_hist, df_pred) %>%
  arrange(Year, Quarter)

# --- 3) Pasar a formato ancho (años x trimestres) ---
value_wide <- df %>%
  select(Year, Quarter, Value) %>%
  pivot_wider(names_from = Quarter, values_from = Value) %>%
  arrange(Year)

flag_wide <- df %>%
  select(Year, Quarter, Pred) %>%
  pivot_wider(names_from = Quarter, values_from = Pred) %>%
  arrange(Year) %>%
  rename(Q1_pred = Q1, Q2_pred = Q2, Q3_pred = Q3, Q4_pred = Q4)

tabla <- value_wide %>%
  left_join(flag_wide, by = "Year")

# --- 4) Tabla interactiva con predicciones coloreadas ---
DT::datatable(
  tabla,
  rownames = FALSE,
  caption = "Emisiones por año y trimestre (millones de toneladas). Las celdas coloreadas son predicciones.",
  options = list(
    pageLength = 50,
    dom = "tip",
    columnDefs = list(
      # Ocultar columnas auxiliares de predicción
      list(visible = FALSE,
           targets = which(names(tabla) %in% c("Q1_pred","Q2_pred","Q3_pred","Q4_pred")) - 1)
    )
  )
) %>%
  formatRound(c("Q1","Q2","Q3","Q4"), 2) %>%
  # Colorear las predicciones usando las columnas *_pred ocultas
  formatStyle('Q1', backgroundColor = styleEqual(c(TRUE, FALSE), c("#e3f2fd", "white")),
              valueColumns = "Q1_pred") %>%
  formatStyle('Q2', backgroundColor = styleEqual(c(TRUE, FALSE), c("#e3f2fd", "white")),
              valueColumns = "Q2_pred") %>%
  formatStyle('Q3', backgroundColor = styleEqual(c(TRUE, FALSE), c("#e3f2fd", "white")),
              valueColumns = "Q3_pred") %>%
  formatStyle('Q4', backgroundColor = styleEqual(c(TRUE, FALSE), c("#e3f2fd", "white")),
              valueColumns = "Q4_pred")

```

##Conclusiones

##Bibliografía
